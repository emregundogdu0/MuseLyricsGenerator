{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2WVeY1bdJGnYGenxmBgBN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kuuQENniMEL5"},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer"]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np"],"metadata":{"id":"dxXCfl-YNSXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","\n","tokenizer = Tokenizer()\n","data = open(\"muse_all_songs.txt\").read()\n","\n","corpus = data.lower().split(\"\\n\")\n","\n","tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(\"word count:\", total_words)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFxCwhzcGkQo","executionInfo":{"status":"ok","timestamp":1754313006797,"user_tz":-180,"elapsed":59,"user":{"displayName":"Emre Gündoğdu","userId":"11995102568587263945"}},"outputId":"f3115047-0daa-4546-d9cc-d2a47718c771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["word count: 2341\n"]}]},{"cell_type":"code","source":["input_sequences = []\n","for line in corpus:\n","\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n","\tfor i in range(1, len(token_list)):\n","\t\tn_gram_sequence = token_list[:i+1]\n","\t\tinput_sequences.append(n_gram_sequence)\n","\n","# pad sequences\n","max_sequence_len = max([len(x) for x in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n","\n","xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n","\n","ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"],"metadata":{"id":"HPDl8OjLGX6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","model = Sequential()\n","model.add(Embedding(total_words, 128, input_length=max_sequence_len - 1))\n","model.add(Bidirectional(LSTM(150, return_sequences=True)))\n","model.add(Dropout(0.2))\n","model.add(LSTM(100))\n","model.add(Dense(total_words, activation='softmax'))\n","\n","adam = Adam(learning_rate=0.001)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","\n","\n","earlystop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n","\n","history = model.fit(xs, ys, epochs=150, verbose=1, callbacks=[earlystop])\n"],"metadata":{"id":"FlfApbM9GZqf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_graphs(history, string):\n","  plt.plot(history.history[string])\n","  plt.xlabel(\"Epochs\")\n","  plt.ylabel(string)\n","  plt.show()"],"metadata":{"id":"6ebbnCzjGa6m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_graphs(history, 'accuracy')\n"],"metadata":{"id":"SDyRTVuQGb1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seed_text = \"your sentence\"\n","next_words = 100\n","\n","for _ in range(next_words):\n","\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n","\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n","\toutput_word = \"\"\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == predicted:\n","\t\t\toutput_word = word\n","\t\t\tbreak\n","\tseed_text += \" \" + output_word\n","print(seed_text)"],"metadata":{"id":"LnswWfI9GdJ1"},"execution_count":null,"outputs":[]}]}